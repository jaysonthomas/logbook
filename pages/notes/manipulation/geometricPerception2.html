
<!DOCTYPE html>
<html>
<head>
  <title>Geometric Perception II</title>
  <meta name="Geometric Perception II" content="text/html; charset=utf-8;" />
  <script type="text/javascript" src="../../../logbook.js"></script>

  <script src="../../../logbook-mathjax-config.js" defer></script> 
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/atom-one-light.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.4.0/mermaid.min.js"></script>
  <script> mermaid.initialize({startOnLoad: true}); </script>  

  <link rel="stylesheet" type="text/css" href="../../../logbook.css" />
</head>

<body onload="loadChapter('');">  

  <div data-type="titlepage" pdf="no">
    <header>
      <h1><a href="../../../index.html" style="text-decoration:none;">Logbook</a></h1>
      <p style="font-size: 18px;"><a href="../../../bio.html">Jayson Wynne-Thomas</a></p>
      <p style="font-size: 14px; text-align: right;"> 
        Last modified <span id="last_modified"></span>.</br>
        <script>
        var d = new Date(document.lastModified);
        document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      </p>
    </header>
  </div>
  
  <div id="main" class="sidebar1">
    <span style="font-size:10px;cursor:pointer" onclick="openNav()">&#9776;</span>
  </div>

  <div id="mySidenav" class="sidebar">
  
<a href="#0">Overview</a>
<a href="#1">ICP Summary</a>
<ul class="no-bullets">
  <li><a href="#1.0">Limitations</a></li>
</ul>
<a href="#2">Point-to-mesh correspondence</a>
<ul class="no-bullets">
  <li><a href="#2.0">Example</a></li>
  <li><a href="#2.1">Algorithm</a></li>
  <li><a href="#2.2">The big picture in using optimisation</a></li>
  <li><a href="#2.3">Algorithm using optimisation</a></li>
</ul>
<a href="#3">Rejecting outliers</a>
<ul class="no-bullets">
  <li><a href="#3.0">Easy case when we are in the last stages of convergence</a></li>
  <li><a href="#3.1">Hard case: Global point registration</a></li>
</ul>
<a href="#4">Global point registration solutions</a>
<ul class="no-bullets">
  <li><a href="#4.0">Segmentation</a></li>
  <li><a href="#4.1">RANSAC - Random Sample Consensus</a></li>
  <li><a href="#4.2">Pairwise distance</a></li>
</ul>
<a href="#5">In-between summary</a>
<a href="#6">Generalise correspondence</a>
</div>

<chapter style="counter-reset: chapter 0"><h1>Geometric Perception II</h1>

<section id="0"><h1>Overview</h1>
  There will be some focus on:
  <ul>
    <li>Estimation due to messy point clouds</li>
    <li>How to use optimisation along with geometry and perception</li>
  </ul>

  We have a rendering pipeline where we simulate rgbd sensors (cameras). We get a colour image and a depth image of the same size which can be transformed into a point cloud. We have an example of an object in its original and perturbed pose i.e. the model and the scene which we matched (using distance as a heuristic) using ICP.
</section>

<section id="1"><h1>ICP Summary</h1>
  The algorithm is iterative because we alternate between two different optimization problems:
  <ul>
    <li>It is assumed that correspondences are known</li>
    We optimise over position and orientation and put in extra constraints.

    <p>
      $
      \displaylines{  
        \text{Given} \: c_i \text{,} \quad
        &\min_{p, R \in \mathbb{R}^{3 \times 3}} 
        \|\underbrace{p + R^0 p^{m_{c_i}}}_{\text{Points projected in} \atop \text{the world frame}}  - 
        
        \underbrace{{}^{W}p^{S_i}}_{\text{Scene points}}\|^2 
        \quad s.t. \;  RR^T=I, det(R)= 1
      }
      $
    </p>

    This problem, when the correspondences are given, has a globally optimal solution (remember the quadratic bowl). It will find the optimal $p$ and $R$ that minimizes the equation. 

    <p>
      <li>It is assumed that a guess at the pose is known</li>
      We reconstruct by searching over possible correspondences. Since we know the pose, we don't have any constraints.
  
      $$
        \displaylines{  
          \text{Given} \: p,R \text{,} \quad
          \min_j 
          \|p + R^0 p^{m_j} - {}^{W}p^{S_i}\|^2 \\
        }
      $$
  
      This is just a minimum distance problem which has good algorithms. Through brute force search or clever nearest neighbor algorithms, we can search over all possible correspondences and find, given the current pose, the best correspondence/the minimum distance. We can also solve this globally and efficiently with good data structures.
    </p>    
  </ul> 
  
  We're going to alternate between the 2 algorithms that are independently global but this alternation can cause local minimum. Alternating between 2 global solvers does not mean that we're solving the joint problem globally. Getting stuck in a local optimum is not just dependent on the shape, but also the initial guess of the pose, number of points etc.

  <p>
    [<a href="https://t.ly/bSbG">Convex problem ref</a>] <br>
    This is a common strategy in optimization used to solve non-convex problems. A few variables are locked in (like $p$ and $R$ in this case) and we solve different pieces of it optimally through alternation strategies. They come up over and over again in bilinear optimization, expectation maximization algorithm etc. We break down a problem that is non-convex into 2 convex problems and alternate. But it can get stuck in local minima because the 2 halves being convex is not enough to solve the original problem jointly.
  </p>

  <subsection id="1.0"><h1>Limitations</h1>
    A common question is, when finding correspondences, is it better to find for every model point a scene point that it corresponds to or for every scene point a model point that it corresponds to. Real point clouds are messy in terms of having dropouts and outliers. Finding a match for an object in a video that is lumpy is hard. 

    <p>
      It's hard if we start with a cad model which has points all over the geometry and we try to find correspondence for every model point to a scene point. We get partial views. Even if we put multiple cameras, we are never going to see the bottom of the object if it's sitting on the table. We are asking the algorithm to correspond to things that just don't exist and that will pull the estimate into the wrong location.
    </p>

    Corresponding scene to model points has problems with outliers. If the camera picks up light returned off of a speck of dust, we get an outlier. There are good demos for these.
  </subsection>
</section>


<section id="2"><h1>Point-to-mesh correspondence</h1>
  A possible solution to both these problems is to identify outliers and remove them from the data set. For example, in partial views scenario, we can reject the model points that are on the back of the mustard bottle. In the outliers scenario, we can remove the actual outliers from the dataset based on some heuristics like distance.

  <p>
    There are subtle reasons to prefer one or the other. Scene to model can be more advantageous because of a generalization of the point-to-point correspondence called point-to-mesh correspondence.
  </p>

  <p>
    A CAD model has triangular meshes and we start by sampling points on them. We then treat them as point registrations. This is a bit weird. Let's say the model was not a set of points but a triangular mesh (one of the 3d geometry representations). 
  </p>

  A <i>triangular mesh</i> contains:
  <ul>
    <li>A list of vertices</li>
    It's not so different from a point cloud. It's a list of xyz locations in space. They could be sparse instead of a dense point cloud.

    <p>A list of faces</p>
    Each face has vertex indices. A bunch of triangular meshes build up the geometry and for every face we have 3 integers that reference the big list of vertices. A <i>face</i> is not a full plane, but just a segment.
  </ul>
  An obj file or an stl file contains these 2 lists. Sometimes they also contain information about normals.

  <subsection id="2.0"><h1>Example</h1>
    <div class="container">
      <figure>
        <img style="height:100px; width:auto"
        src="../../../figures/manipulation/42_pointToMeshCorrespondence.png"/>
        <figcaption>
          Point-to-mesh correspondence example
        </figcaption>
      </figure>
    </div>
    For now, let's say we've got a box in 2d. The list of vertices could be:
    <p>
      [0](-1.5, -1.5)<br>
      [1](-1.5, 1.5) <br>
      [2](1.5, -1.5) <br>
      [3](1.5, 1.5)
    </p>
    <p>
      The list of faces in 2d would be: (0,1), (0,2), (1,3), (2,3). That is we have a face that goes from the $0^{th}$ to the $1^{st}$ vertex.
    </p>

    If we have a scene point that we'd like to register with the CAD model, rather than match it with the closest random sample point on the nearest face, it would be better to find the distance between the point and the face. 
  </subsection>

  <subsection id="2.1"><h1>Algorithm</h1>
    How do we represent a point to a face rather than find closest point to a point? A plane can be defined with the linear equation, $a^Tx = b$. There's a bunch of geometry and derivation that can be applied like taking dot product of the normal vector, that would give different formulations.

    <p>
      But there's a very slick solution based on optimisation. The first observation is that, we can parameterize the position $p$ of any point (blue) inside a face (or a triangular face) by just making an affine combination of the vertices because the set of points will be a convex set.
    </p>

    $$
      p = \sum_i \alpha_i p^{v^F_i} 
      \quad s.t. \quad 0\leq \alpha_i 
      \quad \sum\alpha_i = 1
    $$

    $p^{v^F_i}$ is the position of the vertex $i$ inside some face $F$. The sum includes all the vertices inside some face $F$.

    <p>
      Since we have the condition $\sum\alpha_i = 1$, we end up representing points strictly on a face. In the above example, considering the face between vertices 0 and 1; at vertex 0, $\alpha_0=1$ and $\alpha_1=0$. At vertex 1, $\alpha_0=0$ and $\alpha_1=1$. If a face had just 2 vertices, looking at just the X-axis, we could parameterise each point on the face using $\alpha_0x_0 + \alpha_1x_1$. And if we swept each $\alpha$ between the values of $0$ and $1$ between the 2 vertices, we would tread along the entire face.
    </p>

    This is true in higher dimensions as well. If we have a convex polytope, a member of that convex polytope can be written as an affine combination of its vertices.
  </subsection>

  <subsection id="2.2"><h1>The big picture in using optimisation</h1>

    $$
      \min_{p, R \in \mathbb{R}^{3 \times 3}} 
      \|p + R^0 p^{m_{c_i}}  - {}^{W}p^{S_i}\|^2 
    $$

    The reason we like this sort of objective is that term inside is linear in the decision variables. Therefore, its square is quadratic in the decision variables which makes it convex in decision variables. So ideally, we would like a function that is linear in the decision variables on the inside so it's quadratic when squared.

    <p>
      Also, it worth doing a little extra work to find the right way to add parameters into the model because it can make a huge difference to the optimisation landscape. Making good choices with the model can fundamentally reform the landscape from something that could be very non-convex to something that's convex and an easy optimization problem to solve.
    </p>

    Deep networks work so well that people tend to not think about this as much anymore. But, even with deep networks, it makes the landscape better that the algorithm is going to work a lot better.
  </subsection>

  <subsection id="2.3"><h1>Algorithm using optimisation</h1>
    Given the correspondences $F_i$, 
    $$
      \forall_i \quad
      \min_{p, R, \alpha} 
      \|p + R^0 p^{s_i}  - \sum_j{\alpha_jp^{m^F_j}}\|^2 
    $$

    <p>
      $\forall_i$ means 'for all scene points $i$', we look up the face to correspond to. $p^{m^F_j}$ are the model points in the face that we know are to be corresponded to. $\alpha$ is added in such a way that it's linear in the objective.
    </p>

    We still have the nasty constraints on the equation: $s.t. \;  RR^T=I, det(R)= 1$. But we can do the same tricks as before now and solve in closed form for $p, \alpha$ and $R$ using the SVD trick. This allows us to have a much sparser representation. SVD would also have to account for the extra constraints on $\alpha$: $0\leq \alpha_i$, $\sum\alpha_i = 1$.
  </subsection>
</section>

<section id="3"><h1>Rejecting outliers</h1>
  We can consider this in 2 different scenarios.

  <subsection id="3.0"><h1>Easy case when we are in the last stages of convergence</h1>
    Here, we are inside the ICP loop, we've got a pretty good solution (good pose estimate) and we're just trying to refine it. We don't want a distant point screwing up the optimisation at the very end of our loop.

    <p>
      There are various heuristics that can be used like distance calculation. If a point is beyond some distance threshold, it is treated as an outlier.
    </p>

    Another heuristic is to threshold the number of inliers. If we know beforehand that we expect to have exactly 10 points, then we only fit the 10 closest points. An <i>inlier</i> refers to a point that agrees with the model and an outlier the opposite.
  </subsection>

  <subsection id="3.1"><h1>Hard case: Global point registration</h1>
    The example scenario is of having a CAD model or a point cloud model of a drill and we're trying to solve the global problem of finding the points that match the drill in the scene. The scene has points all over the place and some of them are drill-ish shapes but not a drill. We'll need different tools. We can't just somehow threshold with max distance as its initial guess might rule out the drill right away and we'll never find it. It's a needle (little model) in the haystack (big point cloud) problem.
  </subsection>
</section>

<section id="4"><h1>Global point registration solutions</h1>
  <subsection id="4.0"><h1>Segmentation</h1>
    We could train a deep network to do some initial segmentation. It is possibe to download deep networks that are pre-trained that we can point them at our environment to get a fairly good segmentation right out of the box. Typically we would throw in some of the specific objects we're trying to segment and at least fine-tune a deep network model (pset).

    <p>
      There are geometric algorithms for segmentation too, but they have been eclipsed by deep networks.
    </p>
  </subsection>

  <subsection id="4.1"><h1>RANSAC - Random Sample Consensus</h1>
    We could take random crops of the scene, i.e. randomly subsample -  randomly pick some subset of the pixels. It's a general tool for regression given outliers.

    <p>
      We sample a subset of the data and try to fit. We discard outliers and just do the initial sample a bunch of times and take the best one.  It's a probabilistic type algorithm that has some theoretical guarantees - if sampled enough times, we will eventually get lucky and sample the right thing.
    </p>
  </subsection>

  <subsection id="4.2"><h1>Pairwise distance</h1>
    This is particularly clever and uses our understanding of geometry with optimization. It is invariant to translation and rotation. Let's say we've got 4 model points in the corners of a rectangle. The distances are known. If we change the pose, i.e. perturb it arbitrarily in translation and rotation, the distances in the new point cloud are still going to be the same. So, taking relative measurements in advantageous because they are invariant to pose. Before we have any estimate of the pose, we could look at the pairwise distances and start asking if that's a pairwise distance that could possibly exist in the model. We reject it if it's not possible.

    <p>
      This approach is computationally expensive if we were to do a distance check for every point w.r.t. each point. Also, given 2 points if the distance between them is something that is not to be expected in the model, then one of the 2 points must not be in the mesh.
    </p>

    <subsubsection><h1>Teaser - Luca carloni</h1>
      This is an algorithm that leverages the pairwise distance idea. If a point does not have any edges that is feasible then it can be removed immediately.  But it is possible to do more aggressive pruning by looking at the whole graph that gets constructed out of these.

      $$
        \|p^{s_i} - p^{s_j}\|^2 \in {\text{Relative distances}}
      $$

      We'll add an edge only if the distance between 2 points ($i,j$) is valid. So, we'll end up with points that are fully connected (at least 2 edges), partially connected (less than 2, we need at least 2 since we consider pairwise distances) and not connected. There are approximations that allows us to discard large numbers of points that don't exist in a clique.

      <p>
        This is a neat idea - without having any notion of the pose or the position, we look at pairs of points and reject a bunch of things that couldn't possibly match. 
      </p>

      But, data received from real point clouds is different. For example, rather than just receiving 2 points representing the corner of a box (let's say of length 5), we actually receive lots of points in between so the distance between any 2 points on that edge is actually less than 5 and greater than the minimum resolution of the camera or the minimum noise threshold/floor of the camera.

      <p>
        There are similar ideas to deal with scaling issues i.e. if the scene points are scaled differently from the model points. This is addressed in the teaser paper. If the image is distorted, the only way to deal with this is to calibrate the camera correctly. This is the case with any algorithm. Distortion effects do happen for example if the robot or a person knocks into the camera.
      </p>

      If the scene points of an object are partially occluded, then this algorithm is still robust to that. It will get rid of the points that cause the occlusion and then we left with a point cloud that has fewer points than we would like to do pose estimation. This algorithm wouldn't falsely get rid of correct points.

      <p>
        How many points do we expect to have? Not many. So far, even if people have been trying to apply it to large raw point clouds, there's always a hidden step  within their algorithm that does a subsampling step. Usually, if an algorithm can cope with a dense point cloud, we subsample.
      </p>

      We approach this from a probabilistic viewpoint - get a distribution of possible pairwise distances and get the statistics of the distribution. It would make it less NP hard.
    </subsubsection>
  </subsection>
</section>

<section id="5"><h1>In-between summary</h1>
  We looked at solving messy point clouds using the scene versus model and the point to mesh model. Then we discussed about how do we reject outliers - in the hard case pairwise distance is a nice example of a geometrically inspired algorithm.

  <p>
    Another way to be more robust to messy point clouds is to relax the rigid notion of correspondence in the sense that a point must correspond to another particular point and nothing else.
  </p>
</section>

<section id="6"><h1>Generalise correspondence</h1>
  $$
    min_x \sum_i \| X\; {}^{O}p^{m_{c_i}} - {}^{w}p^{s_i}\|^2
  $$
  If we switch $X\; {}^{O}p^{m_i}$ and ${}^{w}p^{m_{c_i}}$, it doesn't make any difference mathematically - algebraically, we just moved our decision variables on the other side. But, geometrically, in the main equation, we are taking the model points and trying to put them in world coordinates so they match the scene points.

  <p>
    If we were to switch, because of the $X$, we would be taking the scene points and working them into the model coordinates. The difference is are we trying to solve ${}^{W}X^O$ or ${}^{O}X^W$. It's just a difference of which frame we're doing the matching in. It doesn't matter if we do it in the object coordinate or in the world coordinates. Either one is fine.
  </p>

  So far the correspondence has entered the equations in a limited way in the use of $c_i$. It's just an integer in an index of the data we put into the equation. It means $c_i$ has to be $j$ and only $j$. Let's write a different version of this optimization that's just a little bit more flexible and then we can we can soften things.

  <p>
    Let's make a correspondence matrix with the following condition to maintain the same rigid correspondence:
  </p>
  $$
    C_{i,j} = 
    \left\{ 
      \begin{array}{ c l }
        1 & \quad \textrm{if $i$ corresponds to $j$} \\
        0 & \quad \textrm{otherwise}
      \end{array}
    \right.
  $$

  To rewrite the objective, we no longer sum over just $i$. 
  $$
      min_x \sum_i \sum_j C_{i,j} \|X\; {}^{O}p^{m_i} - {}^{W}p^{s_i}\|^2
  $$

  We just multiply by 0 all the points we don't consider to be corresponding, so it's the same as the previous equation, algebraically.
</section>

<button class="accordion">Notes to be written when needed</button>
<div class="panel">
  <p></p>
  this one though as you can see we could then we could start being more flexible with our decision about what's
  corresponding i could have some points that are you know i could have entire rows or columns of j that are completely
  zero if i want to have something that doesn't correspond to anything or i could even have multiple
  points from my model correspond to my scene or multiple points in my scene correspond to my model
  you know there's just a lot more flexibility there 
  
  i can also
  allow partial correspondences right i could say that ci you know model
  point i kind of corresponds with model point or the scene point j right i could set c to be point five or something or point two
  right so this is i can i can relax this hard constraint
  to be like let's say it doesn't even really have to stay inside one but let's just say it stays
  inside there 
  
  similarly like
  you know only match model only matches one
  scene you know this looks like a constraint like the sum over um
  corresponds to depends which one i wrote here so if i say model j
  only corresponds to one scene so this would be sum over i or
  sum over i right and if i wanted to say that the scene some you know only matches one model i
  could put a constraint saying that the sum of over j had to equal one right just the
  columns and rows of that but this is a pretty flexible representation i could add
  constraints to that if i want to impose more rigid matching
  okay 
  
  so the same way that icp
  goes through and tries to compute the correspondences in an outer loop there's a there's another
  well-known algorithm called coherent point drift cpd which given my initial my guess of my
  pose we'll go through and compute kind of a softer distance to compute these cijs
  hold them constant solve the x same way we did before okay
  and then given x solve for my cijs but using just
  a softer version of that that gives me values between 0 and 1. okay
  you
  
  
  so it's still an iterative algorithm
  it will go through and given my current x it will compute cij and now
  coherent point drift the paper is written completely in a bayesian probabilistic framework i'm translating
  i mean you can write anything as a gaussian and it's just a quadratic and vice versa so i've converted it to stay
  in our notation to look just like the quadratic objectives that we know and love um but it's the same it's all the same
  right some you could take any of our quadratic forms and give a probabilistic interpretation
  um okay but um because they have a probabilistic interpretation they choose um a waiting
  function to say two points are um not just the distance but i'm gonna put a gaussian
  kernel okay so i'm going to say that the points are are
  corresponding based on a gaussian kernel that says how close they are to matching okay so i will just pick
  e to the distance basically
  this is a normalization constant to get it all equal to one
  
  1:00
  okay so what does that look like instead of instead of in my i should make a nice little animation of this too in this
  where i had my my animations that look like this
  right i take one step
  you see the little green lines there okay this is actually that's a bad case because there's three
  three scene points that match to that one blue but the but the blue only matches
  right there each each scene point only matches to one blue now think of it as having like a little
  gaussian around each of the points okay and based on the distance i'm going to score all of them all of my neighbors as
  having some weight of correspondence okay that drops off in the shape of a gaussian
  now why is that more robust potentially the word on the street is that it's more robust it tends to be more robust
  outliers and everything first of all that the fact that it tails off
  nicely right it's not just any arbitrary distance it's got an explicit tail where the the points that are far away get
  zero correspondence you know turning towards zero correspondence okay
  and it's it's a softer correspondence it doesn't have to have exactly a one-to-one matching one that's an artificial thing right so you're
  matching you can match up between two points if you're just getting a different sample returns but
  there's lots of reasons maybe to believe that this is a slightly more robust version of the algorithm
  because of the probabilistic interpretation they even have a way to schedule the covariance right so you can you can
  look at your current fit and tighten your covariance estimate so that you're you're dialing in and converging to a to
  a good solution okay
  so this oops
  this paper also has bunnies all over the place like figures one through six are all bunnies stanford bunnies um and
  some people have been have been at stanford before right when you go running around stanford it's
  um the bunnies don't look like that right they're hairs they're like these big you know jackrabbits things so it's kind of funny that the
  they have like a new england bunny or something that's the stanford one button anyhow
  bunnies everywhere and the the evidence in the paper and the i'd
  say consistent feedback from the community is that these algorithms tend to be more robust to outliers and noise
  in this especially in the local convergence sense the downside is that they tend to be much more expensive to compute you're
  looping through a lot more um pairs of points as opposed to just making for every scene point you just
  compute the distance for one you're somehow you're up you're you're computing this thing for every possible
  pair of points and your computer you're using it in your up your pose estimation
  update a lot more terms
  
  1:04
  wei gao who was a student with me not too long ago had a version of it
  that observed that if you flip some of the terms around you can actually get a lot
  of the performance back and he has a cpd-like algorithm called filter reg
  that that was a lot a lot faster right so cpd was like tends to be pretty slow
  but but robust uh he had a version that was pretty fast and pretty robust
  that general idea of soft softening the correspondences make sense
  i feel that a lot of people get confused about cpd because the notation is so different but i really it's just it's just just that
  okay but if i think about that equation there i'll pull it back down
  i've been sort of preaching this you know make good choices i guess i said um
  did we make a good choice here right it's fine for this implementation because we alternate between
  picking cij and then solving for the pose or whatever but
  what immediately jumps out to me is that if i wanted to try to optimize c and x at the same time
  this gets me you know at least closer to thinking about how i would do this there's two sets of
  decision variables that look kind of similar i could potentially throw them into a solver but but those things are being multiplied
  together so i'd have a term that would be you know quadratic in my my terms inside here but multiply it
  again by this this set of decision variables if i wanted to to solve them jointly so that's
  not a good choice in terms of global optimization for the cpd it's great
  so let me do one last um optimization sort of idea with you here okay which would be
  how do i massage this equation one more time to try to get
  the cij to enter in a better way so i could do joint optimization on those things
  
  1:07
  there's a handful of methods that try to make try to solve those problems jointly
  okay here's here's one formulation that is the most i'd say obvious um
  not obvious but most logical successor i guess the closest to that set of equations
  let's try to minimize over p r and c all at the same time
  okay and what if i did this sum over i again here
  let me do the s i here and i'll do
  m
  okay so flex your optimization muscles for a minute here so um
  what is this saying this is saying for every scene point i wanted to you know with my correspondence function
  match some combination of the model points not so different than what we did with the faces okay
  but this is a version of the soft correspondences that you see there too you can add hard constraints on cij or
  you can allow them to be more soft okay you can ask for them to be
  a one to one match from one to many match or many to one match or
  in whichever direction with constraints like this okay
  and it fits inside this nice framework
  the trick with this and the one that i wrote earlier is that these constraints are still bad and once i add these other
  constraints here um you can't just solve the svd
  
  1:09
  so there's various ways that people have have tried to work with these kind of equations okay
  there's a form of it where
  you try to stick to binary correspondences and you can write this whole thing as a
  mixed integer optimization
  is it good forget the relaxation here is still a qp it's definitely mixed integer convex
  okay there are versions of this that use semi-definite programming okay
  if i don't do this okay there's also another version that does semi-definite programming
  these are more advanced optimization algorithms but they're still optimization algorithms that you expect
  to be able to solve globally and they require relaxing these constraints
  a bit to fit them into that framework and there's various levels of success
  for those different algorithms
  right i think so that's what i was just saying is that it's also not a semi-definite program by itself but you
  have to relax this to be yeah both of these require relaxation
  we come up with some approximation of those rotation constraints yeah
  let me just make sure super clear about that
  okay and i won't cover the details i just want to you know get you to think about that equation a
  little bit because it's similar to what we've been thinking about it's another way right there's this kind of skill that you'll pick up of how do you
  fit these harder prop these harder formulations into the same kind of tool kit okay
  this is a good i think way to think about that and know that there are you know papers you can read if you'd like
  to understand the details of how to try to do more global optimization i'd say
  i would not call global optimization of technology and really messy point clouds it's something that people are trying to
  do they're often very expensive they often don't work as well i mean i think luca
  is very keen on the teaser semi-definite programming representation so um
  so maybe it's gotten a lot better the sdp relaxation in in teaser and the like
  i think the way to think about it which i mumbled about last time but it really is
  you know 2d is not enough to show the picture that would need to be shown but i think
  conceptually thinking about this this optimization problem that we showed before and having that
  unit circle constraint okay saying that a squared plus b squared
  equals one
  and we're going to change that to a squared plus b squared less than or equal to 1.
  this picture of trying to solve for these things jointly by relaxing
  the non-convex unit circle constraint to the convex unit disk constraint
  that's that's basically what's happening in these stp relaxations so you'll hear people saying things like
  well it's tight and that's in in the case where there's no noise it's tight because
  the objective function actually lands right on the the unit disk
  okay but if you and you pull it outside this constraint will pull it back inside but if you're inside it will be loose
  so if that's helpful i'm i know that's i haven't given you everything you need to appreciate that but
  if that is helpful i hope it it helps a few people okay 
  
  1:13
  so that was
  today's story about dealing with messy point clouds and about doing a little bit of you know geometry plus
  optimization which i really think is kind of a beautiful combination of those ideas
  right so we talked about three specific ones i hope you come away with this point to mesh registration
  idea with the pairwise distance idea that it's a translation and rotation and
  variant quantity and this idea of generalizing correspondence to make it soft
  paying an increased computational cost but potentially robust getting robustness benefits
  make good choices yeah okay cool um there's one last big set of
  ideas in that i want to make sure we cover in um in pose estimation and we'll do that next tuesday
  sorry the deep node was having troubles this week they were like having i think a
  bad behavior bad actors uh attacking their servers um they're super they're super uh
  responsive actually they told me when it happened and whatever you know they said as of last night it's back up
  so if you have any troubles let me know
</div>

</chapter>

</body>
</html>
