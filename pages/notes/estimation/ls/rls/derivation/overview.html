<!DOCTYPE html>
<html>
<head>
  <title>Overview of the derivation</title>
  <meta name="Overview of the derivation" content="text/html; charset=utf-8;" />
  <script type="text/javascript" src="../../../../../../logbook.js"></script>

  <script src="../../../../../../logbook-mathjax-config.js" defer></script> 
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/atom-one-light.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.4.0/mermaid.min.js"></script>
  <script> mermaid.initialize({startOnLoad: true}); </script>  

  <link rel="stylesheet" type="text/css" href="../../../../../../logbook.css" />
</head>

<body onload="loadChapter('');">  

  <div data-type="titlepage" pdf="no">
    <header>
      <h1><a href="../../../../../../index.html" style="text-decoration:none;">Logbook</a></h1>
      <p style="font-size: 18px;"><a href="../../../../../../bio.html">Jayson Wynne-Thomas</a></p>
      <p style="font-size: 14px; text-align: right;"> 
        Last modified <span id="last_modified"></span>.</br>
        <script>
        var d = new Date(document.lastModified);
        document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      </p>
    </header>
  </div>
  
  <div id="main" class="sidebar1">
    <span style="font-size:10px;cursor:pointer" onclick="openNav()">&#9776;</span>
  </div>

  <div id="mySidenav" class="sidebar">
  
</div>

<chapter style="counter-reset: chapter 0"><h1>Overview of the derivation</h1>
  $$
    \hat{x}_k = \hat{x}_{k-1} + K_k(y_k - H_k\hat{x}_{k-1})
  $$

  Using the above linear recursive formulation, the covariance matrix $P_k$ can be expressed as a function of $K_k$:

  $$
    P_k = (1-K_kH_k)P_{k-1}(1-K_kH_k)^T + K_kR_kK^T_k
  $$  
  
  The cost function of RLS is minimised when its derivative w.r.t. $K_k$ is equal to $0$. This relationship leads to taking derivatives of matrix traces of the various terms in $P_k$ which leads to $K_k$:

  $$
    K_k = P_{k-1}H^T_k(H_kP_{k-1}H^T_k + R_k)^{-1}
  $$
  
  Finally, by using this formulation, the recursive definition for $P_k$ can be further simplified: 

  $$\begin{align*}
    P_k &= P_{k-1} - K_kH_kP_{k-1} \\
    &= (I-K_kH_k)P_{k-1}
  \end{align*}$$
  
  <m>The larger the gain matrix $K$, the smaller the new estimator covariance will be</m>.
</chapter>

</body>
</html>
